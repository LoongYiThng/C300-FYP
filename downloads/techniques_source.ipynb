{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all technique source code\n",
    "### technique authorship\n",
    "*Ayrton's techniques*\n",
    "1. character masking\n",
    "2. synthetic data\n",
    "3. data perturbation  \n",
    "\n",
    "*Yi Thng's techniques*\n",
    "1. record surpression\n",
    "2. generalisation\n",
    "3. data aggregation\n",
    "\n",
    "*Ethan's techniques*\n",
    "1. pseudonymisation\n",
    "2. swapping\n",
    "3. data aggregation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## character masking\n",
    "**description:**  \n",
    "**implementation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "\n",
    "def mask_data(text):\n",
    "    masked_text = ''\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        if is_name(word):  # Mask names\n",
    "            masked_text += mask_name(word) + ' '\n",
    "        elif is_email(word):  # Mask email addresses\n",
    "            masked_text += mask_email(word) + ' '\n",
    "        elif is_number(word):  # Mask numbers (including phone numbers)\n",
    "            masked_text += mask_number(word) + ' '\n",
    "        else:\n",
    "            masked_text += word + ' '\n",
    "    return masked_text.strip()\n",
    "\n",
    "def is_name(word):\n",
    "    # Check if the word is likely to be a name\n",
    "    return word[0].isalpha() and word[0].isupper()\n",
    "\n",
    "def is_email(word):\n",
    "    # Check if the word is likely to be an email address\n",
    "    return '@' in word and '.' in word\n",
    "\n",
    "def is_number(word):\n",
    "    # Check if the word is likely to be a number (including phone numbers)\n",
    "    return word.isdigit() or is_phone_number(word)\n",
    "\n",
    "def is_phone_number(word):\n",
    "    # Check if the word is likely to be a phone number\n",
    "    return any(char.isdigit() for char in word)\n",
    "\n",
    "def mask_name(name):\n",
    "    # Mask a name by replacing characters with 'X'\n",
    "    masked_name = ''\n",
    "    for char in name:\n",
    "        if char.isalnum():\n",
    "            masked_name += 'X'\n",
    "        else:\n",
    "            masked_name += char\n",
    "    return masked_name\n",
    "\n",
    "def mask_email(email):\n",
    "    # Mask an email address by replacing the entire email address with 'X'\n",
    "    return 'X' * len(email)\n",
    "\n",
    "def mask_number(number):\n",
    "    # Mask a number (including phone numbers) by replacing digits with 'X'\n",
    "    return 'X' * len(number)\n",
    "\n",
    "# Open the Word document\n",
    "doc = Document('test.docx')\n",
    "\n",
    "# Process each paragraph in the document\n",
    "for paragraph in doc.paragraphs:\n",
    "    original_text = paragraph.text\n",
    "    masked_text = mask_data(original_text)\n",
    "    paragraph.text = masked_text\n",
    "\n",
    "# Save the modified document\n",
    "doc.save('masked.docx')\n",
    "print(\"Done! Check save folder\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## synthetic data\n",
    "**description:**  \n",
    "**implementation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "from docx import Document\n",
    "\n",
    "faker = Faker()\n",
    "\n",
    "# Example original document\n",
    "document = Document('test.docx')\n",
    "\n",
    "# Function to sanitize text\n",
    "def sanitize_text(text):\n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "    # Generate a fake word for each original word\n",
    "    fake_words = [faker.word() for _ in words]\n",
    "    # Combine the fake words into a string\n",
    "    fake_text = ' '.join(fake_words)\n",
    "    return fake_text\n",
    "\n",
    "# Sanitize the document\n",
    "for paragraph in document.paragraphs:\n",
    "    # Sanitize the text in the paragraph\n",
    "    sanitized_text = sanitize_text(paragraph.text)\n",
    "    # Replace the original text with the sanitized text\n",
    "    paragraph.text = sanitized_text\n",
    "\n",
    "# Save the sanitized document\n",
    "document.save('synthetic.docx')\n",
    "print(\"Done, Check save folder\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data perturbation\n",
    "**description:**  \n",
    "**implementation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "import random\n",
    "import string\n",
    "\n",
    "def perturb_data(text):\n",
    "    perturbed_text = ''\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        if is_name(word):  # Perturb names\n",
    "            perturbed_text += perturb_name(word) + ' '\n",
    "        elif is_email(word):  # Perturb email addresses\n",
    "            perturbed_text += perturb_email(word) + ' '\n",
    "        elif is_number(word):  # Perturb numbers (including phone numbers)\n",
    "            perturbed_text += perturb_number(word) + ' '\n",
    "        else:\n",
    "            perturbed_text += word + ' '\n",
    "    return perturbed_text.strip()\n",
    "\n",
    "def is_name(word):\n",
    "    # Check if the word is likely to be a name\n",
    "    return word[0].isalpha() and word[0].isupper()\n",
    "\n",
    "def is_email(word):\n",
    "    # Check if the word is likely to be an email address\n",
    "    return '@' in word and '.' in word and word.index('@') < word.rindex('.')\n",
    "\n",
    "def is_number(word):\n",
    "    # Check if the word is likely to be a number (including phone numbers)\n",
    "    return word.isdigit() or is_phone_number(word)\n",
    "\n",
    "def is_phone_number(word):\n",
    "    # Check if the word is likely to be a phone number\n",
    "    return any(char.isdigit() for char in word)\n",
    "\n",
    "def perturb_name(name):\n",
    "    # Perturb a name by randomly replacing characters\n",
    "    perturbed_name = ''\n",
    "    for char in name:\n",
    "        if char.isalnum():\n",
    "            perturbed_name += random.choice(string.ascii_letters)\n",
    "        else:\n",
    "            perturbed_name += char\n",
    "    return perturbed_name\n",
    "\n",
    "def perturb_email(email):\n",
    "    # Perturb an email address by randomly changing characters before the '@' symbol\n",
    "    username, domain = email.split('@')\n",
    "    perturbed_username = perturb_name(username)\n",
    "    return perturbed_username + '@' + domain\n",
    "\n",
    "def perturb_number(number):\n",
    "    # Perturb a number (including phone numbers) by randomly changing digits\n",
    "    perturbed_number = ''\n",
    "    for digit in number:\n",
    "        if digit.isdigit():\n",
    "            perturbed_number += random.choice(string.digits)\n",
    "        else:\n",
    "            perturbed_number += digit\n",
    "    return perturbed_number\n",
    "\n",
    "# Open the Word document\n",
    "doc = Document('test.docx')\n",
    "\n",
    "# Process each paragraph in the document\n",
    "for paragraph in doc.paragraphs:\n",
    "    original_text = paragraph.text\n",
    "    perturbed_text = perturb_data(original_text)\n",
    "    paragraph.text = perturbed_text\n",
    "\n",
    "# Save the modified document\n",
    "doc.save('perturbed.docx')\n",
    "print(\"Done! Check save folder\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## record surpression\n",
    "**description:** record surpression refers to the removal of an entire record in the dataset. in contrast to most techniques, this technique affects multiple attributes at the same time  \n",
    "**implementation:** delete an entire record. \"Redacting\" may not be sufficient if the underlying data remains accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "import re\n",
    "\n",
    "regex={\n",
    "    \"email\": \"\\S+@(\\S+|\\.\\S+)\",\n",
    "    \"age\": \"\\d+\\syears\\sold\",\n",
    "    \"money\": \"\\$\\d+(?:\\,\\d+|\\d+)+(?:\\.\\d+)?\",\n",
    "    \"phone number\": \"(?:\\+65|\\+65\\s)?\\d{4}\\s?\\d{4}\",\n",
    "    \"name or place\": \"[A-Z][a-z]+\\s?\"\n",
    "}\n",
    "\n",
    "poor_punctuation=\"^(?:[^\\w\\s]+|\\s+)+$|(?:[^\\w\\s](?:\\s+)?){2,}|[^\\w\\s]{2,}|\\s{2,}\"\n",
    "sanitization_whitespace_remnant=\"\\s\\.\"\n",
    "\n",
    "sensitive_types=[]\n",
    "\n",
    "# define sensitive data\n",
    "def is_sensitive(sentence):\n",
    "    sensitive=False\n",
    "    for key in regex:\n",
    "        if re.search(regex[key], sentence):\n",
    "            sensitive=True\n",
    "            sensitive_types.append(key)\n",
    "    return sensitive\n",
    "\n",
    "def sanitize(sentence, sensitive_types:list):\n",
    "    for i in sensitive_types:\n",
    "        sentence=re.sub(regex[i], \"\", sentence)\n",
    "    return sentence\n",
    "\n",
    "# sanitize\n",
    "doc = Document(\"test.docx\")\n",
    "sanitized_doc=Document()\n",
    "output_paragraph=\"\"\n",
    "\n",
    "for paragraph in doc.paragraphs:\n",
    "    original_text=paragraph.text\n",
    "    sentences=re.split(\"\\.\\s\", original_text)\n",
    "    for sentence in sentences:\n",
    "        if is_sensitive(sentence):\n",
    "            output_paragraph+=sanitize(sentence, sensitive_types)+\". \"\n",
    "        else:\n",
    "            output_paragraph+=sentence\n",
    "        sensitive_types=[]\n",
    "\n",
    "    output_paragraph=re.sub(poor_punctuation, \"\", output_paragraph)\n",
    "    output_paragraph=re.sub(sanitization_whitespace_remnant, \".\", output_paragraph)\n",
    "    if len(output_paragraph)>0:\n",
    "        sanitized_doc.add_paragraph(output_paragraph)\n",
    "    output_paragraph=\"\"\n",
    "\n",
    "# output\n",
    "sanitized_doc.save(\"surpressed.docx\")\n",
    "print(\"Done! check save folder\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generalisation\n",
    "**description:** a reduction in the precision of data by rephrasing into something more vague. for example turning age into a age range or a precise location into a district/country.  \n",
    "**implementation:** design appropriate data categories and rules for translating data and surpress records that still stand out after translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! check save folder\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "import re\n",
    "\n",
    "regex={\n",
    "    \"age\": \"\\d+\\syears\\sold\",\n",
    "    \"money\": \"\\$\\d+(?:\\,\\d+|\\d+)+(?:\\.\\d+)?\",\n",
    "    \"name or place\": \"[A-Z][a-z]+\\s?\"\n",
    "}\n",
    "\n",
    "poor_punctuation=\"^(?:[^\\w\\s]+|\\s+)+$|(?:[^\\w\\s](?:\\s+)?){2,}|[^\\w\\s]{2,}|\\s{2,}\"\n",
    "sanitization_whitespace_remnant=\"\\s\\.\"\n",
    "\n",
    "sensitive_types=[]\n",
    "\n",
    "# define sensitive data\n",
    "def is_sensitive(sentence):\n",
    "    sensitive=False\n",
    "    for key in regex:\n",
    "        if re.search(regex[key], sentence):\n",
    "            sensitive=True\n",
    "            sensitive_types.append(key)\n",
    "    return sensitive\n",
    "\n",
    "def sanitize(sentence, sensitive_types:list):\n",
    "    if \"age\" in sensitive_types:\n",
    "        all_instances=re.findall(regex[\"age\"], sentence)\n",
    "        for matched in all_instances:\n",
    "            age=re.search(\"\\d+\", matched)\n",
    "            age=int(age.group())\n",
    "            sentence=re.sub(re.escape(matched), str(age-10)+\" - \"+str(age+10), sentence)\n",
    "\n",
    "    if \"money\" in sensitive_types:\n",
    "        all_instances=re.findall(regex[\"money\"], sentence)\n",
    "        for matched in all_instances:\n",
    "            money=float(re.sub(\"\\$|,\", \"\", matched))\n",
    "            sentence=re.sub(re.escape(matched), str(money-money*0.2)+\" - \"+str(money+money*0.2), sentence)\n",
    "\n",
    "    if \"name or place\" in sensitive_types:\n",
    "        pass\n",
    "\n",
    "    return sentence\n",
    "\n",
    "# sanitize\n",
    "doc = Document(\"test.docx\")\n",
    "sanitized_doc=Document()\n",
    "output_paragraph=\"\"\n",
    "\n",
    "for paragraph in doc.paragraphs:\n",
    "    original_text=paragraph.text\n",
    "    sentences=re.split(\"\\.\\s\", original_text)\n",
    "    for sentence in sentences:\n",
    "        if is_sensitive(sentence):\n",
    "            output_paragraph+=sanitize(sentence, sensitive_types)+\". \"\n",
    "        else:\n",
    "            output_paragraph+=sentence\n",
    "        sensitive_types=[]\n",
    "\n",
    "    output_paragraph=re.sub(poor_punctuation, \"\", output_paragraph)\n",
    "    output_paragraph=re.sub(sanitization_whitespace_remnant, \".\", output_paragraph)\n",
    "    if len(output_paragraph)>0:\n",
    "        sanitized_doc.add_paragraph(output_paragraph)\n",
    "    output_paragraph=\"\"\n",
    "\n",
    "# output\n",
    "sanitized_doc.save(\"generalized.docx\")\n",
    "print(\"Done! check save folder\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data aggregation\n",
    "**description:** converting a dataset from a list of records to summarised values  \n",
    "**implementation:** statistical measures can be used. typical ways include using totals or averages, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
